from __future__ import print_function
import time
from selenium import webdriver
from bs4 import BeautifulSoup
from urllib.request import Request, urlopen
from urllib.error import HTTPError
import ipdb
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
from pathlib import Path
import sys
from us2020data.webcollect.webscrape_harrismedium import get_president_speech
import pathlib

MONTHS = {"Jan": "1", "Feb": "2", "Mar": "3", "Apr": "4", "May": "5", "Jun": "6", "Jul": "7",
          "Aug": "8", "Sep": "9", "Oct": "10", "Nov": "11", "Dec": "12"}

def get_biden_speech_list(url, chrome_options, keywords=[]):

    browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)    
    req = Request(url, headers={'User-Agent': 'Mozilla/5.0', 'Connection': 'keep-alive',
                        'Pragma': 'no-cache', 'Cache-Control': 'no-cache',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'})
    try:
        ret = urlopen(req)
        http_code = ret.getcode()
    except HTTPError as err:
        browser.quit()
        print("Exciting with error code: {}".format(err.code))
        sys.exit(1)
    else:
        print("HTTP response code: {}".format(http_code))

    browser.get(url)  
    time.sleep(5)    
    lenOfPage = browser.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;") 
    time.sleep(4)
    match=False
    while(match==False):
        lastCount = lenOfPage
        time.sleep(4)
        lenOfPage = browser.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")
        if lastCount==lenOfPage:
            match=True  
    time.sleep(4)
    soup = BeautifulSoup(browser.page_source, "html.parser")
    speeches_out = []
    speech_list = soup.find("main").find_all("article")
    mp = 0

    for speech in speech_list:
        content = speech.find("div", class_="l").find_all("div")
        try:
            date = content[0].find("p").find("span").get_text()
        except:
            date = content[0].find("div").find_all("div")[1].find("div", class_="l").find("p").find_all("span")[1].get_text()
        pdate = pd.Timestamp(date)        
        if pdate.month != int(MONTHS[date.replace(",", "").split()[0]]) \
                or pdate.day != int(date.replace(",", "").split()[1]) \
                or pdate.year != int(date.replace(",", "").split()[2]):
            month = int(MONTHS[date.replace(",", "").split()[0]])
            day = int(date.replace(",", "").split()[1])
            year = pdate.year != int(date.replace(",", "").split()[2])
            pdate = pd.Timestamp(year=year, month=month, day=day)        
        titlepart = content[1].find("a")
        title = content[1].find("h2").get_text().strip()
        if len(keywords) > 0:
            of_interest = [k for k in keywords if k in title.lower()]
            if len(of_interest) == 0:
                continue 
        if "https://medium.com" in titlepart["href"]:
            link = titlepart["href"]
        else:
            link = "https://medium.com{}".format(titlepart["href"])
        try:
            if "Member-only" in content[0].get_text().strip() or\
                  "del-vicepresidente-" in link or\
                      "my-statement-on-vanessa-guill√©n" in link:
                print("member")
                print(link)
                mp += 1
                continue
        except:
            pass
        date = pdate        
        speeches_out.append((title, date, link))
        print(link)

    browser.quit()
    print(mp)
    return speeches_out

      
if __name__ == "__main__":

    cwd = pathlib.Path.cwd()
    DIR_out = "{}/medium/".format(cwd)
    Path(DIR_out).mkdir(parents=True, exist_ok=True)
    url = "https://medium.com/@JoeBiden/"

    dataset = {"SpeechID": [], "POTUS": [], "Date": [], "SpeechTitle": [], "RawText": [], "SpeechURL": [], "Summary": [], "Source": []}
    
    print("Starting collecting speeches from: {}...".format(url))
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.headless = True
    chrome_options.add_argument('--disable-extensions')
    chrome_options.add_argument('--profile-directory=Default')
    chrome_options.add_argument("--incognito")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("window-size=1280,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) "
                                "Chrome/44.0.2403.157 Safari/537.36")
    keywords = []
    potusspeech_cnt = 0
    speech_id_init = "MEJB"
    
    speeches_out = get_biden_speech_list(url, chrome_options, keywords)
    for i in speeches_out:
        if (i[1] < pd.Timestamp("2019-01-01")) or (i[1] > pd.Timestamp("2021-01-31")):
            continue
        dataset["POTUS"].append("Joe Biden")
        dataset["Date"].append(i[1])
        dataset["SpeechTitle"].append(i[0])        
        speechurl = i[2]
        dataset["SpeechURL"].append(speechurl)
        dataset["Source"].append("Joe Biden Medium")
        title = i[0]
        print(speechurl)           
        datetimestamp, source, summary, transcript, speechID = get_president_speech("Joe Biden", speechurl, 
                                                    chrome_options, potusspeech_cnt=potusspeech_cnt, 
                                                    speech_id_init=speech_id_init, date=i[1])
        potusspeech_cnt = potusspeech_cnt + 1
        print(speechurl)
        print(title)
        print(speechID)        
        dataset["Summary"].append(summary)
        dataset["RawText"].append(transcript)
        dataset["SpeechID"].append(speechID)
        
        time.sleep(2)

    datasetout_df = pd.DataFrame.from_dict(dataset)
    print(datasetout_df)
    d = datasetout_df.sort_values(['Date'],ascending=True).groupby('POTUS')
    datasetout_df = d.head(len(datasetout_df)).reset_index(drop=True) 
    datasetout_df.to_csv("{}/rawtext_JoeBiden.tsv".format(DIR_out), index=False, sep="\t")
